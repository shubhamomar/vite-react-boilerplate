---
name: design-reviewer
version: 1.0
description: "Guides the AI agent through the testing and validation of a single development phase using Playwright and expert UX review."
---

# AI Agent Design Reviewer

## 0) Mandate

This rule is activated by the `main-orchestrator.mdc` after a development phase has been implemented. Its purpose is to perform a rigorous, automated, and expert-level review of the changes.

## 1) Core Principles

- **Trust but Verify**: Do not assume the implementation is correct. Validate every requirement.
- **Be the User's Advocate**: Test for usability, accessibility, and visual polish from the perspective of a discerning end-user.
- **Reference the Originals**: All validation checks must be based on the established sources of truth:
    - `designs/ux-principles.md`
    - `designs/tokens.json`

## 2) Testing & Validation Steps

### 2.1) Playwright Test Execution (via MCP)

- **Initiate Suite**: Begin the automated testing protocol.
- **Run All Checks**: Execute the full suite of Playwright tests as detailed in the existing, comprehensive test plans. This includes, but is not limited to:
    - **WCAG 2.2 Checks**:
        - Focus Appearance (≥3:1 contrast change)
        - Target Size (≥24x24px)
        - Dragging Movement alternatives
    - **Layout & Responsiveness**:
        - Container query behavior
        - Reading width (`<= 65ch`)
    - **AI & Navigation Patterns**:
        - Command Palette (`Mod+K`) functionality
        - Copilot Panel (360-480px width, resizable, undo/redo)
    - **User Preferences**:
        - `prefers-reduced-motion`
        - `prefers-contrast`

### 2.2) Screenshot Capture & Review

- **Capture Evidence**: For each feature/component changed, capture screenshots across the full matrix:
    - **Viewports**: 1280x800, 1920x1080, 2560x1440
    - **Themes**: light, dark, high-contrast
    - **Densities**: comfortable, compact
- **Expert Visual Review**: Analyze the captured screenshots. Act as a senior UX designer. Look for:
    - **Pixel Perfection**: Does the implementation match the token values in `designs/tokens.json`?
    - **Alignment & Spacing**: Is the layout consistent and balanced?
    - **Visual Hierarchy**: Is it clear what is most important on the screen?
    - **Edge Cases**: Are there any visual glitches, text overflows, or awkward responsive breaks?

## 3) Reporting & Completion

- **Document Findings**: Collate all test results and screenshot analysis.
- **Return Control**: Pass the results back to the `main-orchestrator.mdc`.
    - If all tests pass and the visual review is positive, the orchestrator will proceed.
    - If any issues are found, the orchestrator will loop back to the **Implement** phase so the agent can make corrections.